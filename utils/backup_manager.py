"""
–ú–æ–¥—É–ª—å –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
"""

import os
import shutil
import sqlite3
import gzip
import json
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any
import threading
import time
import asyncio

from utils.logger import get_logger

logger = get_logger(__name__)

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º DATA_DIR –∏–∑ config –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å CI –∏ Docker
try:
    from config import DATA_DIR
except ImportError:
    # Fallback –¥–ª—è —Ç–µ—Å—Ç–æ–≤ –µ—Å–ª–∏ config –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω
    DATA_DIR = Path("./data")


class BackupConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –±—ç–∫–∞–ø–æ–≤"""

    def __init__(self):
        # –û—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (—á–∏—Ç–∞–µ–º –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞)
        self.BACKUP_ENABLED = os.getenv("BACKUP_ENABLED", "true").lower() == "true"
        self.BACKUP_INTERVAL_HOURS = int(os.getenv("BACKUP_INTERVAL_HOURS", "6"))  # –ö–∞–∂–¥—ã–µ 6 —á–∞—Å–æ–≤

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º DATA_DIR –∏–∑ config –≤–º–µ—Å—Ç–æ hardcoded /app/data
        default_backup_dir = DATA_DIR / "backups"
        self.BACKUP_DIR = Path(os.getenv("BACKUP_DIR", str(default_backup_dir)))

        # –†–æ—Ç–∞—Ü–∏—è –±—ç–∫–∞–ø–æ–≤
        self.KEEP_HOURLY_BACKUPS = int(os.getenv("KEEP_HOURLY_BACKUPS", "48"))  # 2 –¥–Ω—è –ø–æ—á–∞—Å–æ–≤—ã—Ö
        self.KEEP_DAILY_BACKUPS = int(os.getenv("KEEP_DAILY_BACKUPS", "30"))  # 30 –¥–Ω–µ–π –µ–∂–µ–¥–Ω–µ–≤–Ω—ã—Ö
        self.KEEP_WEEKLY_BACKUPS = int(os.getenv("KEEP_WEEKLY_BACKUPS", "12"))  # 12 –Ω–µ–¥–µ–ª—å –µ–∂–µ–Ω–µ–¥–µ–ª—å–Ω—ã—Ö
        self.KEEP_MONTHLY_BACKUPS = int(os.getenv("KEEP_MONTHLY_BACKUPS", "6"))  # 6 –º–µ—Å—è—Ü–µ–≤ –µ–∂–µ–º–µ—Å—è—á–Ω—ã—Ö

        # –°–∂–∞—Ç–∏–µ –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
        self.COMPRESS_BACKUPS = os.getenv("COMPRESS_BACKUPS", "true").lower() == "true"
        self.BACKUP_ENCRYPTION = os.getenv("BACKUP_ENCRYPTION", "false").lower() == "true"
        self.MAX_BACKUP_SIZE_MB = int(os.getenv("MAX_BACKUP_SIZE_MB", "1000"))  # 1GB –ª–∏–º–∏—Ç

        # –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö - –∏—Å–ø–æ–ª—å–∑—É–µ–º DATA_DIR
        default_db_path = DATA_DIR / "coworking.db"
        self.DB_PATH = Path(os.getenv("DB_PATH", str(default_db_path)))


class BackupMetadata:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –±—ç–∫–∞–ø–æ–≤"""

    def __init__(self, backup_dir: Path):
        self.backup_dir = backup_dir
        self.metadata_file = backup_dir / "backup_metadata.json"
        self._metadata = self._load_metadata()

    def _load_metadata(self) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –±—ç–∫–∞–ø–æ–≤"""
        if self.metadata_file.exists():
            try:
                with open(self.metadata_file, "r", encoding="utf-8") as f:
                    return json.load(f)
            except Exception as e:
                logger.error(f"Error loading backup metadata: {e}")

        return {
            "backups": [],
            "last_cleanup": None,
            "total_backups_created": 0,
            "failed_backups": 0,
        }

    def _save_metadata(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö"""
        try:
            with open(self.metadata_file, "w", encoding="utf-8") as f:
                json.dump(self._metadata, f, indent=2, ensure_ascii=False, default=str)
        except Exception as e:
            logger.error(f"Error saving backup metadata: {e}")

    def add_backup(self, backup_info: Dict[str, Any]):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –Ω–æ–≤–æ–º –±—ç–∫–∞–ø–µ"""
        self._metadata["backups"].append(backup_info)
        self._metadata["total_backups_created"] += 1
        self._save_metadata()

    def remove_backup(self, backup_name: str):
        """–£–¥–∞–ª–µ–Ω–∏–µ –±—ç–∫–∞–ø–∞ –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö"""
        self._metadata["backups"] = [
            b for b in self._metadata["backups"] if b.get("filename") != backup_name
        ]
        self._save_metadata()

    def record_failed_backup(self, error_message: str):
        """–ó–∞–ø–∏—Å—å –Ω–µ—É–¥–∞—á–Ω–æ–≥–æ –±—ç–∫–∞–ø–∞"""
        self._metadata["failed_backups"] += 1
        self._metadata["last_error"] = {
            "timestamp": datetime.utcnow().isoformat(),
            "error": error_message,
        }
        self._save_metadata()

    def get_backups(self) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö –±—ç–∫–∞–ø–æ–≤"""
        return self._metadata.get("backups", [])

    def get_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –±—ç–∫–∞–ø–æ–≤"""
        backups = self._metadata.get("backups", [])
        if not backups:
            return {
                "total_backups": 0,
                "total_created": self._metadata.get("total_backups_created", 0),
                "failed_backups": self._metadata.get("failed_backups", 0),
                "last_backup": None,
                "total_size_mb": 0,
            }

        last_backup = max(backups, key=lambda x: x.get("created_at", ""))
        total_size = sum(b.get("size_bytes", 0) for b in backups)

        return {
            "total_backups": len(backups),
            "total_created": self._metadata.get("total_backups_created", 0),
            "failed_backups": self._metadata.get("failed_backups", 0),
            "last_backup": last_backup,
            "total_size_mb": round(total_size / (1024 * 1024), 2),
        }


class DatabaseBackupManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""

    def __init__(self):
        self.config = BackupConfig()
        self.backup_dir = self.config.BACKUP_DIR
        self.backup_dir.mkdir(parents=True, exist_ok=True)
        self.metadata = BackupMetadata(self.backup_dir)
        self._backup_lock = threading.Lock()
        self._scheduler_running = False
        self._scheduler_task = None

    def create_backup(self, backup_type: str = "scheduled") -> Optional[Dict[str, Any]]:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö

        Args:
            backup_type: –¢–∏–ø –±—ç–∫–∞–ø–∞ (scheduled, manual, pre_update)

        Returns:
            –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–æ–∑–¥–∞–Ω–Ω–æ–º –±—ç–∫–∞–ø–µ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        with self._backup_lock:
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –ë–î
                if not self.config.DB_PATH.exists():
                    error_msg = f"Database file not found: {self.config.DB_PATH}"
                    logger.error(error_msg)
                    self.metadata.record_failed_backup(error_msg)
                    return None

                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –±—ç–∫–∞–ø–∞
                timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
                backup_filename = f"coworking_backup_{timestamp}_{backup_type}.db"

                if self.config.COMPRESS_BACKUPS:
                    backup_filename += ".gz"

                backup_path = self.backup_dir / backup_filename

                logger.info(f"Starting database backup: {backup_filename}")

                # –°–æ–∑–¥–∞–µ–º –±—ç–∫–∞–ø
                success = self._perform_backup(self.config.DB_PATH, backup_path)

                if not success:
                    error_msg = "Backup creation failed"
                    self.metadata.record_failed_backup(error_msg)
                    return None

                # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ
                file_size = backup_path.stat().st_size

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä
                if file_size > self.config.MAX_BACKUP_SIZE_MB * 1024 * 1024:
                    logger.warning(f"Backup size {file_size} exceeds limit")

                backup_info = {
                    "filename": backup_filename,
                    "type": backup_type,
                    "created_at": datetime.utcnow().isoformat(),
                    "size_bytes": file_size,
                    "size_mb": round(file_size / (1024 * 1024), 2),
                    "compressed": self.config.COMPRESS_BACKUPS,
                    "db_path": str(self.config.DB_PATH),
                }

                # –î–æ–±–∞–≤–ª—è–µ–º –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                self.metadata.add_backup(backup_info)

                logger.info(
                    f"Database backup created: {backup_filename}",
                    extra={
                        "event_type": "backup",
                        "backup_type": backup_type,
                        "size_mb": backup_info["size_mb"],
                    },
                )

                logger.info(
                    f"Backup created successfully: {backup_filename} ({backup_info['size_mb']} MB)"
                )

                return backup_info

            except Exception as e:
                error_msg = f"Backup creation error: {e}"
                logger.error(error_msg, exc_info=True)
                self.metadata.record_failed_backup(error_msg)
                return None

    def _perform_backup(self, source_db: Path, backup_path: Path) -> bool:
        """
        –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ñ–∏–∑–∏—á–µ—Å–∫–æ–≥–æ –±—ç–∫–∞–ø–∞ –ë–î

        Args:
            source_db: –ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–π –ë–î
            backup_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –±—ç–∫–∞–ø–∞

        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, False –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        try:
            # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –∏—Å—Ö–æ–¥–Ω–æ–π –ë–î
            source_conn = sqlite3.connect(str(source_db))

            if self.config.COMPRESS_BACKUPS:
                # –°–æ–∑–¥–∞–µ–º —Å–∂–∞—Ç—ã–π –±—ç–∫–∞–ø
                with gzip.open(backup_path, "wb") as gz_file:
                    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π –±—ç–∫–∞–ø –≤ –ø–∞–º—è—Ç–∏
                    temp_backup = sqlite3.connect(":memory:")
                    source_conn.backup(temp_backup)

                    # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤ SQL –∏ —Å–∂–∏–º–∞–µ–º
                    sql_dump = ""
                    for line in temp_backup.iterdump():
                        sql_dump += line + "\n"

                    gz_file.write(sql_dump.encode("utf-8"))
                    temp_backup.close()
            else:
                # –°–æ–∑–¥–∞–µ–º –Ω–µ—Å–∂–∞—Ç—ã–π –±—ç–∫–∞–ø
                backup_conn = sqlite3.connect(str(backup_path))
                source_conn.backup(backup_conn)
                backup_conn.close()

            source_conn.close()
            return True

        except Exception as e:
            logger.error(f"Error performing backup: {e}")
            return False

    def restore_backup(
        self, backup_filename: str, target_db: Optional[Path] = None
    ) -> bool:
        """
        –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ë–î –∏–∑ –±—ç–∫–∞–ø–∞

        Args:
            backup_filename: –ò–º—è —Ñ–∞–π–ª–∞ –±—ç–∫–∞–ø–∞
            target_db: –¶–µ–ª–µ–≤–∞—è –ë–î (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å—Ö–æ–¥–Ω–∞—è)

        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ
        """
        try:
            backup_path = self.backup_dir / backup_filename

            if not backup_path.exists():
                logger.error(f"Backup file not found: {backup_filename}")
                return False

            if target_db is None:
                target_db = self.config.DB_PATH

            logger.info(f"Starting database restore from: {backup_filename}")

            # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é —Ç–µ–∫—É—â–µ–π –ë–î
            if target_db.exists():
                backup_current = target_db.with_suffix(".db.backup")
                shutil.copy2(target_db, backup_current)
                logger.info(f"Current database backed up to: {backup_current}")

            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏–∑ –±—ç–∫–∞–ø–∞
            success = self._perform_restore(backup_path, target_db)

            if success:
                logger.info(
                    f"Backup restored successfully to: {target_db}",
                    extra={"event_type": "backup", "backup_type": "restore"},
                )
                return True
            else:
                # –ï—Å–ª–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—É—é –ë–î
                if target_db.with_suffix(".db.backup").exists():
                    shutil.move(target_db.with_suffix(".db.backup"), target_db)
                    logger.info("Original database restored after failed restore")
                return False

        except Exception as e:
            logger.error(f"Error restoring backup: {e}", exc_info=True)
            return False

    def _perform_restore(self, backup_path: Path, target_db: Path) -> bool:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ñ–∏–∑–∏—á–µ—Å–∫–æ–≥–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è"""
        try:
            if str(backup_path).endswith(".gz"):
                # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏–∑ —Å–∂–∞—Ç–æ–≥–æ –±—ç–∫–∞–ø–∞
                with gzip.open(backup_path, "rb") as gz_file:
                    sql_content = gz_file.read().decode("utf-8")

                # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—É—é –ë–î
                if target_db.exists():
                    target_db.unlink()

                # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –ë–î –∏–∑ SQL
                conn = sqlite3.connect(str(target_db))
                conn.executescript(sql_content)
                conn.close()
            else:
                # –ü—Ä–æ—Å—Ç–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
                shutil.copy2(backup_path, target_db)

            return True

        except Exception as e:
            logger.error(f"Error performing restore: {e}")
            return False

    def cleanup_old_backups(self) -> Dict[str, int]:
        """
        –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤ - —É–¥–∞–ª—è–µ—Ç –≤—Å–µ –∫—Ä–æ–º–µ —Å–∞–º–æ–≥–æ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ

        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—á–∏—Å—Ç–∫–∏
        """
        logger.info(
            "Starting backup cleanup - removing all backups except the latest one"
        )

        backups = self.metadata.get_backups()
        deleted_count = 0
        deleted_size = 0

        if len(backups) <= 1:
            logger.info("No backups to clean up (0 or 1 backup found)")
            return {"deleted_count": 0, "deleted_size_mb": 0.0}

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –±—ç–∫–∞–ø—ã –ø–æ –¥–∞—Ç–µ —Å–æ–∑–¥–∞–Ω–∏—è (–Ω–æ–≤—ã–µ —Å–Ω–∞—á–∞–ª–∞)
        backups.sort(key=lambda x: x.get("created_at", ""), reverse=True)

        # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å–∞–º—ã–π –ø–æ—Å–ª–µ–¥–Ω–∏–π –±—ç–∫–∞–ø (–ø–µ—Ä–≤—ã–π –≤ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–º —Å–ø–∏—Å–∫–µ)
        latest_backup = backups[0]
        backups_to_delete = backups[1:]  # –í—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ

        logger.info(
            f"Keeping latest backup: {latest_backup['filename']} ({latest_backup['created_at']})"
        )
        logger.info(f"Will delete {len(backups_to_delete)} old backups")

        for backup in backups_to_delete:
            try:
                backup_path = self.backup_dir / backup["filename"]
                if backup_path.exists():
                    file_size = backup_path.stat().st_size
                    backup_path.unlink()
                    deleted_size += file_size
                    deleted_count += 1
                    logger.info(
                        f"Deleted old backup: {backup['filename']} ({backup['created_at']})"
                    )
                else:
                    logger.warning(
                        f"Backup file not found on disk: {backup['filename']}"
                    )

                # –£–¥–∞–ª—è–µ–º –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                self.metadata.remove_backup(backup["filename"])

            except Exception as e:
                logger.error(
                    f"Error deleting backup {backup.get('filename', 'unknown')}: {e}"
                )

        # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        self.metadata._metadata["last_cleanup"] = datetime.utcnow().isoformat()
        self.metadata._save_metadata()

        cleanup_stats = {
            "deleted_count": deleted_count,
            "deleted_size_mb": round(deleted_size / (1024 * 1024), 2),
        }

        logger.info(
            f"Backup cleanup completed: {deleted_count} files deleted ({cleanup_stats['deleted_size_mb']} MB)",
            extra={"event_type": "backup", "backup_type": "cleanup"},
        )

        return cleanup_stats

    async def start_scheduler(self):
        """–ó–∞–ø—É—Å–∫ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –±—ç–∫–∞–ø–æ–≤"""
        if not self.config.BACKUP_ENABLED:
            logger.info("üìÇ Backup scheduler disabled by configuration")
            return

        if self._scheduler_running:
            logger.warning("Backup scheduler already running")
            return

        self._scheduler_running = True

        logger.info(
            f"üìÇ Starting backup scheduler: interval {self.config.BACKUP_INTERVAL_HOURS}h"
        )

        # –°–æ–∑–¥–∞–µ–º –ø–µ—Ä–≤—ã–π –±—ç–∫–∞–ø –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
        await asyncio.get_event_loop().run_in_executor(
            None, self.create_backup, "startup"
        )

        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–π –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫
        self._scheduler_task = asyncio.create_task(self._scheduler_loop())

    async def stop_scheduler(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞"""
        self._scheduler_running = False
        if self._scheduler_task:
            self._scheduler_task.cancel()
            try:
                await self._scheduler_task
            except asyncio.CancelledError:
                pass
        logger.info("Backup scheduler stopped")

    async def _scheduler_loop(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞"""
        try:
            while self._scheduler_running:
                await asyncio.sleep(self.config.BACKUP_INTERVAL_HOURS * 3600)

                if not self._scheduler_running:
                    break

                # –°–æ–∑–¥–∞–µ–º –±—ç–∫–∞–ø
                await asyncio.get_event_loop().run_in_executor(
                    None, self.create_backup, "scheduled"
                )

                # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –±—ç–∫–∞–ø—ã —Ä–∞–∑ –≤ –¥–µ–Ω—å
                current_hour = datetime.utcnow().hour
                if current_hour == 2:  # –í 2 –Ω–æ—á–∏ –ø–æ UTC
                    await asyncio.get_event_loop().run_in_executor(
                        None, self.cleanup_old_backups
                    )

        except asyncio.CancelledError:
            logger.info("Backup scheduler loop cancelled")
        except Exception as e:
            logger.error(f"Error in backup scheduler loop: {e}", exc_info=True)

    def get_backup_status(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ —Å—Ç–∞—Ç—É—Å–∞ —Å–∏—Å—Ç–µ–º—ã –±—ç–∫–∞–ø–æ–≤"""
        stats = self.metadata.get_stats()

        return {
            "enabled": self.config.BACKUP_ENABLED,
            "scheduler_running": self._scheduler_running,
            "backup_interval_hours": self.config.BACKUP_INTERVAL_HOURS,
            "backup_dir": str(self.backup_dir),
            "stats": stats,
            "config": {
                "compress_backups": self.config.COMPRESS_BACKUPS,
                "keep_hourly": self.config.KEEP_HOURLY_BACKUPS,
                "keep_daily": self.config.KEEP_DAILY_BACKUPS,
                "keep_weekly": self.config.KEEP_WEEKLY_BACKUPS,
                "keep_monthly": self.config.KEEP_MONTHLY_BACKUPS,
                "max_size_mb": self.config.MAX_BACKUP_SIZE_MB,
            },
        }


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –±—ç–∫–∞–ø–æ–≤
backup_manager = DatabaseBackupManager()


# –ü—É–±–ª–∏—á–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏
async def start_backup_scheduler():
    """–ó–∞–ø—É—Å–∫ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ –±—ç–∫–∞–ø–æ–≤"""
    await backup_manager.start_scheduler()


async def stop_backup_scheduler():
    """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ –±—ç–∫–∞–ø–æ–≤"""
    await backup_manager.stop_scheduler()


async def restart_backup_scheduler():
    """–ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ –±—ç–∫–∞–ø–æ–≤ —Å –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    global backup_manager
    try:
        # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—É—â–∏–π –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫
        await backup_manager.stop_scheduler()
        logger.info("Backup scheduler stopped")
        
        # –ñ–¥–µ–º –Ω–µ–º–Ω–æ–≥–æ –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–æ–º
        import asyncio
        await asyncio.sleep(1)
        
        # –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ —Ñ–∞–π–ª–∞
        from pathlib import Path
        import json
        config_file = Path("config") / "backup_config.json"
        if config_file.exists():
            with open(config_file, 'r') as f:
                saved_config = json.load(f)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
            for key, value in saved_config.items():
                os.environ[key] = value
            logger.info("Backup configuration reloaded from file")
        
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –º–µ–Ω–µ–¥–∂–µ—Ä–∞ —Å –Ω–æ–≤–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
        backup_manager = DatabaseBackupManager()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ —Å –Ω–æ–≤—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
        await backup_manager.start_scheduler()
        logger.info("Backup scheduler restarted with new configuration")
        return True
        
    except Exception as e:
        logger.error(f"Failed to restart backup scheduler: {e}")
        return False


def create_manual_backup() -> Optional[Dict[str, Any]]:
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ä—É—á–Ω–æ–≥–æ –±—ç–∫–∞–ø–∞"""
    return backup_manager.create_backup("manual")


def get_backup_status() -> Dict[str, Any]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ —Å–∏—Å—Ç–µ–º—ã –±—ç–∫–∞–ø–æ–≤"""
    return backup_manager.get_backup_status()


def list_available_backups() -> List[Dict[str, Any]]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –±—ç–∫–∞–ø–æ–≤"""
    return backup_manager.metadata.get_backups()


def restore_from_backup(backup_filename: str) -> bool:
    """–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ë–î –∏–∑ –±—ç–∫–∞–ø–∞"""
    return backup_manager.restore_backup(backup_filename)


def cleanup_backups() -> Dict[str, int]:
    """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤"""
    return backup_manager.cleanup_old_backups()
